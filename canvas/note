关于图形学
1. 数据可视化
2. 在线文档
3. 3d应用
4. 人工智能
5. 游戏方向
6. AR VR
Canvas 2D
一个像素点显示到屏幕上的过程 
参考自https://zhuanlan.zhihu.com/p/32136704
一个从编程/输入设备输入到显示器显示到人眼的完整过程。分为几个阶段：（应用程序/输入设备产生）数据与指令——>CPU——>显卡驱动程序——>显卡——>显示器——>人眼。
1. 显示器阶段
拿常见的液晶显示器举例，显示器是的底部是一块发光白板灯，中间液晶，然后是一些滤光片。
简单理解液晶显示器成像的原理就是，背光的光线发出，经过液晶分子的控制，最终形成了人眼看到图像，那么液晶分子是如何控制光线的呢？
这也很好理解，液晶不是固态，也不是液态，而是一种中间的状态，其分子在电压的控制下，形成不同的排列方式，所以可以控制光线的透过，形成不同明暗程度的画面，这是一个非常重要的步骤，如果只能形成一明一暗是构成不了画面的.不管是显示器还是投影机，其实都是按这个原理进行显示的。当然如果只是进行了上述的过程，形成的画面仅仅是黑白画面，因为透过液晶分子的光线并没有颜色，需要滤色片来“上色”。
显示器的屏幕是由很多个“小块”组成的，每块后面都有红绿蓝三个滤光片，每个小块就是1个像素点。滤光片能够把显示器背后发出的白光过滤，留下单色光通过，白光经过三块滤光片后被分解成了红绿蓝三束光，进入人的眼睛。由于一个像素极其小，三个滤光片距离极其近，以至于透过它们的光进入人眼后，人眼分不清这是3束光，即光在人眼中发生混色作用，于是一个像素便“有了”颜色。这3束光强度如果一致的话，混色后人眼将会看到白色光，而想要看到五颜六色的话，混合前的红绿蓝三束光应该具有不同强度(亮度)，如何获得不同亮度的三色光呢？这就是液晶作用了。
显示器底部的背光材质，其主要负责发射白光，这些光线通过液晶分子的控制，形成黑白画面，由于有了滤色片，所以显示器实现了彩色的效果。
所以，大家需要注意的一点是：通过液晶分子的光线其实并没有颜色，需要滤色片来“上色”。这恐怕是大多数网友都不了解的一个原理。
由于电压信号是连续变化的（举个栗子，从200变为201是连续变化的，而不是跳跃地一下子从200变为201），而我们知道计算机只认识0和1，内部是由0和1二进制来表示的，表示的数据是离散化的(从200跳跃到201)，前者我们称之为模拟信号，后者称为数字信号。把承载有计算机数据的数字信号转为显示器用的模拟信号，这个过程就是数模转换了，而执行这个过程的设备，就是显卡了。
显卡是实现数模转换的重要器件。
2. 显卡阶段
• 显卡硬件：关于显卡，这里直接引用下百度百科：
显卡全称显示接口卡，又称显示适配器，是计算机最基本配置、最重要的配件之一。显卡作为电脑主机里的一个重要组成部分，是电脑进行数模信号转换的设备，承担输出显示图形的任务。显卡接在电脑主板上，它将电脑的数字信号转换成模拟信号让显示器显示出来，同时显卡还是有图像处理能力，可协助CPU工作，提高整体的运行速度。显卡有不同类型，内部工作原理不尽相同，而同一个操作系统可以安装在不同显卡的机器上，如何识别它们，让不同显卡都能在此操作系统下正常工作，需要一个在操作系统与（显卡）硬件间沟通者的角色，这个就是（显卡）驱动程序了。
数据从离开CPU到达显示屏，中间必须通过如下4个步骤：
1．从总线进入GPU（图形处理器）：将CPU送来的数据送到北桥，再送到GPU里面进行处理。
2．将芯片处理完的数据送到显存。
3．从显存读取出数据再送到随机读写存储数模转换器进行数模转换的工作。（但是如果是DVI接口类型的显卡，则不需要经过数字信号转模拟信号。而直接输出数字信号。）
4．从DAC进入显示器：将转换完的模拟信号送到显示屏。
显卡就是起数据处理和数模转换的作用。
3. 数据输入
• 键盘
从理论上，我可以用键盘按照一定的编码敲出一长串0、1数字序列，再加一个jpg/png的后缀名保存。打开文件时，是将这些数据送入内存，图片查看程序控制CPU，根据后缀名对数据进行解码、解压后得到图像本身的数据——每个像素的RGB等。再历经前面所述的一大串过程，CPU的数据再经过显卡和显示器，最终我就能看到一张滑稽的照片。
• 应用程序
除了我们直接用拍照的方式记录下一副图片的信息之外，还有另一种主要的方式，就是通过计算机程序。毕竟，计算机不是照相机。
例如，写了一个程序，实现了在屏幕画一条线，或者显示一个圆柱体，或者显示一个怪物模型。本质上我们都是要获得表示一幅二维图像的一串0和1的数字，而我们知道的一些数据，例如线段长度、圆柱体的半径高度、怪物表面部分点的坐标、我们从什么角度来观察这些物体，那么，怎样获得这幅图像的信息呢？这就是图形学的范畴了。
但本质上，图形学的API底层都会提供一个类似于drawPixel(int x, int y, Color color)的接口，用于实现将屏幕坐标为(x,y)的像素点颜色设置为color的功能。
4. 总结
在操作系统与硬件驱动程序的帮助下，用户通过输入设备或者程序向计算机CPU发送一系列的数据，这些数字信号再经过显卡变为不断变化的电压模拟信号，电压控制了液晶的滤光性，像素背后的白光被分成了强弱不同的三原色光，再经人眼的混色作用使得一个像素具有了千变万化的颜色。
5. GPU与CPU
CPU和GPU之所以大不相同，是由于其设计目标的不同，它们分别针对了两种不同的应用场景。CPU需要很强的通用性来处理各种不同的数据类型，同时又要逻辑判断又会引入大量的分支跳转和中断的处理。这些都使得CPU的内部结构异常复杂。而GPU面对的则是类型高度统一的、相互无依赖的大规模数据和不需要被打断的纯净的计算环境。
GPU采用了数量众多的计算单元和超长的流水线，但只有非常简单的控制逻辑并省去了Cache。而CPU不仅被Cache占据了大量空间，而且还有有复杂的控制逻辑和诸多优化电路，相比之下计算能力只是CPU很小的一部分。
CPU有强大的ALU（算术运算单元）,它可以在很少的时钟周期内完成算术计算。
CPU擅长逻辑控制，串行的运算。
GPU擅长的是大规模并发计算，这也正是密码破解等所需要的。所以GPU除了图像处理，也越来越多的参与到计算当中来。
GPU的工作大部分就是这样，计算量大，但没什么技术含量，而且要重复很多很多次。就像你有个工作需要算几亿次一百以内加减乘除一样，最好的办法就是雇上几十个小学生一起算，一人算一部分，反正这些计算也没什么技术含量，纯粹体力活而已。而CPU就像老教授，积分微分都会算，就是工资高，一个老教授资顶二十个小学生，你要是富士康你雇哪个？GPU就是这样，用很多简单的计算单元去完成大量的计算任务，纯粹的人海战术。这种策略基于一个前提，就是小学生A和小学生B的工作没有什么依赖性，是互相独立的。很多涉及到大量计算的问题基本都有这种特性，比如你说的破解密码，挖矿和很多图形学的计算。这些计算可以分解为多个相同的简单小任务，每个任务就可以分给一个小学生去做。但还有一些任务涉及到“流”的问题。比如你去相亲，双方看着顺眼才能继续发展。总不能你这边还没见面呢，那边找人把证都给领了。这种比较复杂的问题都是CPU来做的。
总而言之，CPU和GPU因为最初用来处理的任务就不同，所以设计上有不小的区别。而某些任务和GPU最初用来解决的问题比较相似，所以用GPU来算了。GPU的运算速度取决于雇了多少小学生，CPU的运算速度取决于请了多么厉害的教授。教授处理复杂任务的能力是碾压小学生的，但是对于没那么复杂的任务，还是顶不住人多。当然现在的GPU也能做一些稍微复杂的工作了，相当于升级成初中生高中生的水平。但还需要CPU来把数据喂到嘴边才能开始干活，究竟还是靠CPU来管的。
canvas
路径--> 点的集合
Webgl-->浏览器开放的面向GPU编程的接口